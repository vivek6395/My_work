Workflow of Retrieval Augmented Generation
3 part – ingestion, retrieval, generation
1.	Data Ingestion:
This stage involves fetching and preparing the data for use in the retrieval and generation processes. 
Step 1: Fetching Data from Confluence Page
•	The data is sourced from a Confluence page and made available for further processing.
Step 2: Pre-processing the Data
•	The data undergoes pre-processing, such as removing unnecessary elements (e.g., Korean text) and applying consistent formatting.
Step 3: Data Chunking
•	The pre-processed data is split into smaller, manageable chunks. These chunks will later be used for matching with the user’s query.
Step 4: Creating Vector Embeddings
•	Generate two types of vector embeddings for the chunked data:
o	Dense vector embeddings for semantic search.
o	Sparse vector embeddings for keyword-based search.

2.	Retrieval:
This stage focuses on retrieving the most relevant information from the ingested data based on the user's query.

Step 5: User Query Input
•	The user submits a query to the system.
Step 6: Hybrid Search
•	A hybrid search is performed by combining both dense (semantic) and sparse (keyword-based) vector embeddings.
•	This search returns 16 relevant data chunks based on the query.
Step 7: Reranking
•	Since language models often prioritize initial and final portions of content, a reranker is used to reorder those retrieved 16 chunks.
•	The top 5 most relevant chunks are selected for the next stage.


3.	Generation:
•	This is where the final response is generated by combining the query with the retrieved context.
Step 8: Response Generation
•	The system creates a prompt by combining the user’s query with the top 5 relevant chunks retrieved from the vector database.
•	This prompt is fed into the large language model (LLM), which generates the final response to the user’s query.

Common Settings and configuration
Prompt message = [
    {
        "role": "system",
        "content": "You are a helpful and knowledgeable AI assistant with expertise in mobile development, AI, machine learning, compilers, and related technical fields. You are tasked with responding to the user's request using only the provided information. The information is sourced from Confluence pages, which may contain high-level technical details. Provide a concise and accurate response based on the given information. Do not mention or reference how the information was obtained or use any phrases that reveal the context's origin. If the provided information is insufficient to fulfil the request, respond with 'I don't know the answer."
    },
    {
        "role": "user",
        "content": "Request: {question}. Please analyse the following context chunks from Confluence and provide the appropriate response: {context}"
    }
]

Dense_vector_Embedding_model = mixedbread-ai/mxbai-embed-large-v1
Sprase_vector_embedding_model=bm25
Reranker_model = cross-encoder/ms-marco-MiniLM-L-12-v2
Vector_db = qdrant
Llm model = llama3.1:8b-instruct-fp16 from ollama (requires approx 16gb vram of gpu)

Question -1: Write a summary about Android R Porting Guide
Hybrid_with_1750_chunk (9): 
Based on the provided context chunks, here is a summary of the Android R Porting Guide:
Overview
The Android R Porting Guide is a document that outlines the steps and procedures for porting the Android R operating system to the KITT device. The guide is maintained by the SSIR team and is updated regularly.
Key Components
The guide covers the following key components:
1.	EDEN: The EDEN framework is a critical component of the Android R porting process. The guide provides information on how to update the EDEN code, including the EDEN stub and Eden driver.
2.	Driver Code Update: The guide provides instructions on how to update the driver code, including the reference repository and branch information.
3.	Eden Core Update: The guide provides instructions on how to update the Eden core code, including the reference repository and branch information.
4.	Eden Runtime Update: The guide provides instructions on how to update the Eden runtime code, including the reference repository and branch information.
5.	Sepolicy Update: The guide provides instructions on how to update the sepolicy, including the addition of module names to the PRODUCT_PACKAGE variable.
Dev Flow
The dev flow for the Android R porting guide is as follows:
1.	Write document
2.	Internal review
3.	ASPICE POC review (led by Seunghwan Lee)
Progress and Next Steps
The guide provides regular updates on the progress of the Android R porting process, including the completion of tasks and the identification of issues. The next steps for the Android R porting process are outlined in the guide, including the update of the EDEN core and Eden projects.
Resources
The guide provides a list of resources, including the names and components of team members, as well as the status of tasks and issues.
Overall, the Android R Porting Guide is a comprehensive document that provides detailed instructions and information on how to port the Android R operating system to the KITT device.

Hybrid_with_1500_chunk (10):
Based on the provided context chunks, here is a summary of the Android R Porting Guide:
Overview
The Android R Porting Guide is a document that outlines the steps and procedures for porting the Android R operating system to the KITT platform. The guide is maintained by the SSIR team and is used to track progress and issues related to the porting process.
Key Components
The guide covers the following key components:
1.	EDEN: The EDEN framework is a critical component of the KITT platform, and the guide provides information on how to port EDEN to Android R.
2.	DD: The DD (Digital Driver) component is also a key part of the KITT platform, and the guide provides information on how to port DD to Android R.
3.	NPU: The NPU (Neural Processing Unit) is a critical component of the KITT platform, and the guide provides information on how to port NPU to Android R.
Porting Process
The porting process involves several steps, including:
1.	Code updates: The guide provides information on how to update the EDEN and DD code to work with Android R.
2.	Build setup: The guide provides information on how to set up the build environment for Android R on the KITT platform.
3.	Testing: The guide provides information on how to test the ported code and identify any issues.
Resources
The guide provides a list of resources, including:
1.	Repositories: The guide provides information on the repositories used for the porting process.
2.	Branches: The guide provides information on the branches used for the porting process.
3.	JIRA issues: The guide provides information on the JIRA issues related to the porting process.
Timeline
The guide provides a timeline for the porting process, including:
1.	Milestones: The guide provides information on the milestones achieved during the porting process.
2.	Issues: The guide provides information on the issues encountered during the porting process.
Overall, the Android R Porting Guide provides a comprehensive overview of the steps and procedures involved in porting the Android R operating system to the KITT platform.
.
Hybrid_with_1250_chunk (10):
Based on the provided context chunks, here is a summary of the Android R Porting Guide:
Overview
The Android R Porting Guide is a document that outlines the steps and procedures for porting Android R to the KITT platform. The guide covers various aspects of the porting process, including EDEN code updates, driver code updates, and Eden runtime updates.
EDEN Code Update
The EDEN code update involves updating the EDEN stub and Eden driver code. The reference repository is located at 10.166.101.43, and the branch is exynosauto9_dev_r. The updated code should be checked in to the repository and built successfully before submitting the changes.
Driver Code Update
The driver code update involves updating the enn_driver code. The reference repository is located at 10.166.101.43, and the branch is s-enn-driver-topic. The updated code should be checked in to the repository and built successfully before submitting the changes.
Eden Runtime Update
The Eden runtime update involves updating the Eden runtime HIDL interface. The reference repository is located at 10.166.101.43, and the branch is exynosauto9_dev_r. The updated code should be checked in to the repository and built successfully before submitting the changes.
Porting Process
The porting process involves the following steps:
1.	EDEN code update
2.	Driver code update
3.	Eden runtime update
4.	Building and testing the updated code
5.	Submitting the changes to the repository
Timeline
The timeline for the porting process is not explicitly mentioned in the provided context chunks. However, based on the updates and progress made by the team members, it appears that the porting process has been ongoing since September 2020 and is still in progress.
Team Members
The team members involved in the porting process include:
•	Khushbu Angirashkumar Patel
•	Sagnik Basu
•	Deepika Boya
•	B Shreenidhi Acharya
•	Ramesh Katuri
•	Femy Varghese
•	Harshit Srivastava
Resources
The resources required for the porting process include:
•	Reference repositories (10.166.101.43)
•	Branches (exynosauto9_dev_r, s-enn-driver-topic)
•	Build tools and testing frameworks
•	CI/CD infrastructure
Note that this summary is based on the provided context chunks and may not be comprehensive or up-to-date.

Hybrid_with_1000_chunk (10):	

Based on the provided Confluence pages, here is a summary of the Android R Porting Guide:
Overview
The Android R Porting Guide is a document that outlines the steps and plan for porting Android R to the KITT platform. The guide is maintained by Khushbu Angirashkumar Patel and other team members.
Steps and Plan
The steps and plan for Android R porting include:
1.	EDEN code update: Update the EDEN code in the repository, including the EDEN stub and Eden driver.
2.	Driver Code Update: Update the driver code in the repository, including the enn_driver project.
3.	Eden Core Update: Update the Eden core code in the repository, including the eden_core project.
4.	Eden Runtime update: Update the Eden runtime code in the repository.
5.	NPU DD porting: Port the NPU DD to Android R.
6.	VTS issue resolution: Resolve the VTS issue related to the NPU DD.
7.	KITT testing: Test the EDEN and DD on the KITT platform.
Resources
The resources required for Android R porting include:
1.	EDEN code update: Check in the updated EDEN code in the repository.
2.	Driver Code Update: Check in the updated driver code in the repository.
3.	Eden Core Update: Check in the updated Eden core code in the repository.
4.	Eden Runtime update: Check in the updated Eden runtime code in the repository.
5.	NPU DD porting: Port the NPU DD to Android R.
6.	VTS issue resolution: Resolve the VTS issue related to the NPU DD.
7.	KITT testing: Test the EDEN and DD on the KITT platform.
Team Members
The team members involved in the Android R porting guide include:
1.	Khushbu Angirashkumar Patel
2.	Sagnik Basu
3.	Deepika Boya
4.	Ramesh Katuri
5.	B Shreenidhi Acharya
Next Week Plan
The next week plan for Android R porting includes:
1.	EDEN framework Code walk through and try to resolve one Gtest/CTS/VTS issue.
2.	Plan and setup KITT andoird R environment for EDEN and DD porting.
3.	Root cause analysis of HCP3-6564.
4.	Continue DD documentation study.
Note: The above summary is based on the provided Confluence pages and may not be a comprehensive guide to Android R porting.

Question -2: Write a step by step process for kittvs evt2 veloce linux boot.
Hybrid_with_1750_chunk (8): 

To perform the kittv2 evt2 veloce linux boot, follow these steps:
1.	Update the DB path to /user/fimgemul/SSIR_USER/users/femy.vk/kittv2-evt2/veloce_20221021_rev3/.
2.	Update the Makefile in veloce_20221021_rev2/ by uncommenting line #265 (echo "xterm & " >>./run_emul.$(MODE).csh).
3.	Update the run_veloce.do script in veloce_20221021_rev2/ by:
o	Disabling traceupload_enable (line #8) to prevent Linux boot from taking too much time.
o	Enabling code_link and xwave if required.
o	If you're not getting the Linux console, perform the following changes:
	rm./veloce.wave/CDB1/rtlc.out/top_GlobalPrecision and cp./veloce.med/rtlc.out/top_GlobalPrecision./veloce.wave/CDB1/rtlc.out/.
	Check the last lines of the run_veloce.do script:
run
#run 500us
#waitfor runcomplete
#quit -f
4.  Run `veloce` from the DB path: `/user/fimgemul/SSIR_USER/users/femy.vk/kittv2-evt2/veloce_20221021_rev3`.
5.  In the xterm, give the following commands:
    ```bash
setenv PATH $PATH:/user/velocemgr/SW/HYCON/HYCON_20191112/bin  
hycon-ssh  
mount -t tmpfs none /vendor/firmware/  
exit  
hycon-scp../debug-ncp/* hycon:/vendor/firmware/
6.	From the QEMU UART, perform the following steps:
cd /vendor/firmware/
./npu_app_v2_quadra --ncp ncp.bin --input in.bin --output out.bin
7.  Copy the Warpcore_boot bins from the specified location:
    ```bash
Copy Warpcore_boot bins from /user/fimgemul.lsi/Methodology/IP_HYBRID/PROJECT/KITT2_EVT2/0_release/veloce_20220926_rev0.exportDB/ENV_VEL/sw_images/linux/

ENV_VEL/sw_images/linux/warpcoreboot.bin,
ENV_VEL/sw_images/linux/warpcoreboot.elf
8.	Update the kernel image and dtb file paths in source_veloce.sw_image.
9.	Update ENV_VEL/hycon/warpcore-common.linux.config with the new kernel image and dtb file paths.
10.	Perform the memory mapping as specified in the table:
warpcore -accesstype sw -start 0x0 -end 0x0FFFFFFF -cpu cluster_0 -debugaccess rw
#warpcore -accesstype hw -start 0x70000000 -end 0x7FFFFFFF -cpu cluster_0 -debugaccess rw # // For preventing memory hole
#warpcore -accesstype sw -start 0x100000000 -end 0x10FFFFFFF -cpu cluster_0 -debugaccess rw # // For preventing memory hole
#warpcore -accesstype hw -start 0xc0200000 -end 0xc0200FFF -cpu cluster_0 -debugaccess rw
11. Set up the V920 SADK board as specified in the reference.
12. Perform the recovery USB boot mode/flash device binary as specified in the refere

Hybrid_with_1500_chunk (9):
Based on the provided context chunks, here is a step-by-step process for KITTv2 EVT2 Veloce Linux boot:
Step 1: Update Makefile and run_veloce.do
1.	Update veloce_20221021_rev2/Makefile by uncommenting line #265 (echo "xterm & " >>./run_emul.$(MODE).csh) to view the xterm window on Veloce run.
2.	Update veloce_20221021_rev2/run_veloce.do by:
o	Disabling traceupload_enable (line #8) to prevent Linux boot from taking too much time.
o	Enabling code_link and xwave if required.
o	If you are not getting the Linux console, perform the following changes:
	rm./veloce.wave/CDB1/rtlc.out/top_GlobalPrecision
	cp./veloce.med/rtlc.out/top_GlobalPrecision./veloce.wave/CDB1/rtlc.out/
o	Check the last lines of the run_veloce.do script.
Step 2: Run Veloce from DB path
1.	Run Veloce from the DB path: /user/fimgemul/SSIR_USER/users/femy.vk/kittv2-evt2/veloce_20221021_rev3
Step 3: Update kernel image and dtb file paths
1.	Copy Warpcore_boot bins from /user/fimgemul.lsi/Methodology/IP_HYBRID/PROJECT/KITT2_EVT2/0_release/veloce_20220926_rev0.exportDB/ENV_VEL/sw_images/linux/
o	ENV_VEL/sw_images/linux/warpcoreboot.bin
o	ENV_VEL/sw_images/linux/warpcoreboot.elf
2.	Update kernel image and dtb file paths in source_veloce.sw_image
3.	Update ENV_VEL/hycon/warpcore-common.linux.config
Step 4: Build and run Linux kernel
1.	Build the Linux kernel using the command: make -j25 ARCH=arm64
2.	Use the CROSS_COMPILE path: /user/velocemgr/SW/CROSSTOOLS/aarch64-unknown-linux-gnueabi/bin/aarch64-unknown-linux-gnueabi-
3.	Run the Linux kernel on the Veloce board.
Step 5: Test app and ncp
1.	Copy the test app and ncp from /user/fimgemul/SSIR_USER/users/femy.vk/kittv2-evt2/debug-ncp/
2.	Run the test app and ncp on the Veloce board.
Note: The above steps are based on the provided context chunks and might not be a comprehensive guide for KITTv2 EVT2 Veloce Linux boot.

Hybrid_with_1250_chunk (10):
Based on the provided context chunks, I will provide a step-by-step process for KITTv2 EVT2 Veloce Linux boot.
Step 1: Update the Makefile and run_veloce.do script
1.	Go to the DB path: /user/fimgemul/SSIR_USER/users/femy.vk/kittv2-evt2/veloce_20221021_rev3/
2.	Update the Makefile by uncommenting line #265 (echo "xterm & " >>./run_emul.$(MODE).csh)
3.	Update the run_veloce.do script by:
o	Disabling traceupload_enable (line #8)
o	Enabling code_link and xwave if required
o	If not getting Linux console, do the following changes:
	rm./veloce.wave/CDB1/rtlc.out/top_GlobalPrecision
	cp./veloce.med/rtlc.out/top_GlobalPrecision./veloce.wave/CDB1/rtlc.out/
Step 2: Run Veloce from the DB path
1.	Run run from the DB path: /user/fimgemul/SSIR_USER/users/femy.vk/kittv2-evt2/veloce_20221021_rev3/
Step 3: Set up the environment and copy the test app and ncp
1.	In the xterm window, set the environment by running: setenv PATH $PATH:/user/velocemgr/SW/HYCON/HYCON_20191112/bin
2.	Run hycon-ssh and mount the /vendor/firmware/ directory
3.	Copy the test app and ncp by running: hycon-scp../debug-ncp/* hycon:/vendor/firmware/
Step 4: Run the test app on the QEMU UART
1.	From the QEMU UART, run: cd /vendor/firmware/
2.	Run the test app by running: ./npu_app_v2_quadra --ncp ncp.bin --input in.bin --output out.bin
Step 5: Analyze the code link wave
1.	Go to the code link wave directory: /user/fimgemul/SSIR_USER/users/femy.vk/kittv2-evt2/veloce_20221021_rev3/veloce.wave/bkup_debug_xwave.gnpu_dsp_0.stw/
Note: The above steps are based on the provided context chunks and may not be a comprehensive guide for KITTv2 EVT2 Veloce Linux boot.
Hybrid_with_1000_chunk (10):

To perform a kittv2 evt2 veloce linux boot, follow these steps:
1.	Update the Makefile in the veloce_20221021_rev2 directory by uncommenting line #265 (echo "xterm & " >>./run_emul.$(MODE).csh) to view the xterm window during the veloce run.
2.	Update the run_veloce.do script in the veloce_20221021_rev2 directory:
o	Disable traceupload_enable (line #8) to prevent Linux boot from taking too much time.
o	Enable code_link and xwave if required.
o	If you're not getting the Linux console, perform the following changes:
	Remove the top_GlobalPrecision file in the rtlc.out directory.
	Copy the top_GlobalPrecision file from the rtlc.out directory in the veloce.med directory to the rtlc.out directory in the veloce.wave/CDB1 directory.
3.	Update the last lines of the run_veloce.do script:
run
#run 500us
#waitfor runcomplete
#quit -f
4. Update the `source_veloce` script to use the correct kernel image and dtb file paths.
5. Update the `ENV_VEL/hycon/warpcore-common.linux.config` file to include the correct memory mapping settings.
6. Copy the `warpcoreboot.bin` and `warpcoreboot.elf` files from the `ENV_VEL/sw_images/linux` directory to the `ENV_VEL/sw_images/linux` directory on the Veloce machine.
7. Update the kernel image and dtb file paths in the `source_veloce.sw_image` file.
8. Run the `source_veloce` script and execute the `make run MODE=veloce` command to start the Veloce machine.
9. In the QEMU UART terminal, log in as `root` without a password and execute the `npu_app_v2_quadra` command to run the NPU test app.
10. From the xterm terminal, push the NCP and FW to the device using the `hycon-scp` command.
11. Once the NCP and FW are pushed, you can run the NPU test app and verify its functionality.


Question -3: how to enable gki in kitt npu dd
Hybrid_with_1750_chunk (9): 
B Based on the provided context chunks, it appears that enabling GKI in KITT NPU DD involves making changes to the Makefile and Kconfig.
Here are the steps to enable GKI in KITT NPU DD:
1.	Build the driver as a kernel loadable module.
2.	Change the Kconfig to use "tristate" instead of "bool".
3.	If the driver consists of multiple source code, make your own ko module name.
Additionally, it is recommended to check with Ankit Goel/ML Solution about SEPolicy changes.
Please note that the provided information is based on the given context chunks, and it may not be a comprehensive guide to enabling GKI in KITT NPU DD.

Hybrid_with_1500_chun (7):
Based on the provided context, to enable GKI in KITT NPU DD, follow these steps:
1.	Makefile and Kconfig changes:
o	Your driver should be built as a Kernel Loadable Module.
o	Change "Bool" to "Tristate" in Kconfig.
o	For example, change config PINCTRL_SAMSUNG from bool to tristate.
2.	If your driver consists of a single source code, you don't need to change the Makefile.
o	However, if your driver consists of multiple source codes and you want to make a single ko file, you should make your own ko module name.
3.	As per context 3, Sagnik Basu has already done the changes for GKI and the build is fine. Testing is going on.
4.	Refer to context 5, which lists the KITT Specific changes in NPU DD. These changes include enabling vGEN/S2MPU, updating the DD version, and fixing various issues.
5.	Context 8 mentions that GKI for NPU DD is a priority task.
 Hybrid_with_1250_chunk (10):
To enable GKI in KITT NPU DD, follow these steps:
1.	Makefile and Kconfig changes:
o	Your driver should be built as a Kernel Loadable Module.
o	In Kconfig, change "Bool" to "Tristate" for the PINCTRL_SAMSUNG configuration.
o	If your driver consists of a single source code, you don't need to change the Makefile.
o	If your driver consists of multiple source codes and you want to make a single ko file, you should make your own ko module name.
2.	Changes in the KITT NPU DD code:
o	The following commits have been made to enable GKI in KITT NPU DD:
	[feat] npu: enable vGEN/S2MPU (change sysmmu vid to AND)
	update dd version - the version is the gerrit id per common repo
	[fix] npu: smc-npu filter replace for pass-through-smc
	[fix] npu: fix dnc stop sequence add soft reset enable to cpu off sequence
	[fix] npu: code alignment -Align with Linux kernel driver
	[fix] npu: static analysis -5948
	npu: static analysis -5946
	[fix] npu: Fix kfree error in invalid NCP handling
3.	Build and test the KITT NPU DD code:
o	Build the KITT NPU DD code in the KITT environment.
o	Test the NPU DD code in Linux.
Note: The above steps are based on the provided context chunks and might not be a comprehensive guide to enable GKI in KITT NPU DD.

Hybrid_with_1000_chunk (9):

To enable GKI (Generic Kernel Interface) in KITT NPU DD (Device Driver), follow these steps based on the provided context chunks:
1.	Make necessary Makefile and Kconfig changes:
o	Ensure your driver is built as a Kernel Loadable Module.
o	Change bool to tristate in the Kconfig file for the PINCTRL_SAMSUNG driver.
o	If your driver consists of a single source code, you don't need to change the Makefile.
2.	Review the KITT specific changes in NPU DD (context 5):
o	These changes include enabling vGEN/S2MPU, updating the DD version, fixing SMC-NPU filter, and static analysis.
3.	Check the KITT2 NPU Safety Patches (context 7):
o	These patches include implementing SM210 CA53 SECDED DDATA POST, adding parity and ECC POST SMs, and refactoring the cmdq interface and ncp task.
4.	Verify that the build is completed and flashing is pending (context 4).
5.	Review the status of Android R integration and Eden testing (context 8):
o	Eden integration is done, and Eden testing is in progress with 3 models enabled for NPU KITT.
By following these steps, you should be able to enable GKI in KITT NPU DD.


Question -4: what is the credential for swc gerrit
Hybrid_with_1750_chunk (10): 
Based on the provided context, the credential for swc Gerrit is as follows:
•	Gerrit server: http://10.166.101.43:81/ (context 6)
•	Username: femy.vk (context 3)
•	Password: Not provided in the context
•	SSH host: swc_gerrit (context 3)
o	HostName: secteamworks.co.kr
o	Port: 29418
o	User: femy.vk
Note that the password is not provided in the context, and you may need to obtain it separately.
.
Hybrid_with_1500_chunk (7):

Based on the provided context, the credential for swc gerrit is 'femy.vk'.

Hybrid_with_1250_chunk (10):
Based on the provided context, the credential for swc Gerrit is as follows:
•	For new members, the credential requires approval from the Corporate VP (Chulmin Jo) and the Technical Leader of the requester (e.g., Rahul Sharma).
•	For old members, the credential only requires approval from the Technical Leader of the requester (e.g., Rahul Sharma).
•	The consent for accessing the Gerrit server is required from SLSI Gerrit (gerrit.slsi@samsung.com).
•	The notification for accessing the Gerrit server is sent to Configuration Management (scm.slsi@samsung.com) and SW Service3 (swsvc3.sec@samsung.com).
The access authorization form needs to be added along with the Knox Approval request. The form should be filled with the details of the TL, requester information, and the git/Gerrit repo and branch for which the access is being requested.
The Gerrit server URL is http://10.166.101.43:81/.
 Hybrid_with_800_chunk (8) :
Based on the provided context chunks, the credential for swc Gerrit is:
•	Gerrit server: http://10.166.211.148:8084 (or https://automotive-gerrit.samsungds.com/)
•	SSH public key: needs to be added to the Gerrit server (http://10.227.36.179:8084/dashboard/self)
•	Access authorization form: needs to be added along with the Knox Approval request
•	Approval: Technical Leader of the requester
•	Consent: SLSI Gerrit (gerrit.slsi@samsung.com)
•	Notification: Configuration Management (scm.slsi@samsung.com), SW Service3 (swsvc3.sec@samsung.com)
Question-5: what is snc explain it in details
Hybric_with_1750_chunk (8):

What is SNC?
SNC stands for Secured Network Container as IR (Intermediate Representation). It is a format used to represent network models, including graph information, data information, and model input/output information.
Key Features of SNC:
1.	Profiler Time Reduction: SNC reduces profiler time by allowing parallel running and framework protocol independence.
2.	FP16 Compile Time Reduction: SNC reduces FP16 compile time by optimizing the compilation process.
3.	SCVT Traversal Time Reduction: SNC reduces SCVT traversal time by optimizing the traversal process.
4.	Error Handling: SNC provides a standardized error handling mechanism, making it easier to track and categorize errors.
5.	Static Information Embedding: SNC allows static information from each layer to be embedded as meta-information, making it easier to track and analyze model behavior.
6.	Unit Testing: SNC provides a unit testing framework, making it easier to test and validate model behavior.
7.	Fine-Grained Control: SNC provides fine-grained control over the compilation process, making it easier to optimize and customize model behavior.
8.	Custom Layer Support: SNC supports custom layer creation, making it easier to embed user code in the middle of the model.
Components of SNC:
1.	SNC Layer: A block that holds data transformation meta-data.
2.	SNC Edge: A block that transmits information from one layer to another without modifying the data.
3.	SNC Tensor: A data abstraction containing data, tensor type, and meta-data.
4.	SNC Module: An abstraction that has many layers, modules, and edges.
5.	SNC Model: An abstraction that doesn't have outside connections and holds layers connection graph on the inside.
SNC API:
The SNC API provides a set of functions and classes that can be used to interact with SNC models. The API is divided into two main parts: C++ and Python.
Usage of SNC API:
1.	C++: The C++ folder contains all C++ related source code. The CMake build system is used to automate building the code into a shared library.
2.	Python: The Python folder contains Python wrapper code on top of the C++ version of the SNC API. The pybind folder contains the Python wrapper code, and the setup.py file is used to auto-install the SNC API as a Python package.
Benefits of SNC:
1.	Improved Profiler Time: SNC reduces profiler time by allowing parallel running and framework protocol independence.
2.	Improved FP16 Compile Time: SNC reduces FP16 compile time by optimizing the compilation process.
3.	Improved SCVT Traversal Time: SNC reduces SCVT traversal time by optimizing the traversal process.
4.	Improved Error Handling: SNC provides a standardized error handling mechanism, making it easier to track and categorize errors.
5.	Improved Static Information Embedding: SNC allows static information from each layer to be embedded as meta-information, making it easier to track and analyze model behavior.
6.	Improved Unit Testing: SNC provides a unit testing framework, making it easier to test and validate model behavior.
7.	Improved Fine-Grained Control: SNC provides fine-grained control over the compilation process, making it easier to optimize and customize model behavior.
8.	Improved Custom Layer Support: SNC supports custom layer creation, making it easier to embed user code in the middle of the model.


Hybrid_with_1500_chunk (9):
What is SNC?
SNC stands for Secured Network Container, which is an Intermediate Representation (IR) of a neural network model. It includes network model information such as the model framework, original model name, graph information, feature map, and weight values.
Key Features of SNC:
1.	Configurable
2.	Easy to find inflection point in case of issues
3.	Fine-grained control possible with SNC in full chain
4.	Custom layer support is easy, and it's easy to embed user code in the middle of the model
5.	The same network (SNC) can be maintained, and each layer does not need to be modified
Components of SNC:
1.	SncLayer: Any block that holds data transformation metadata
o	Holds one or more input connections using input edges array
o	Holds one or more output connections using output edges array
o	Holds tensors like weights and bias by name using a dictionary/map
o	Holds layer optype and parameters data to transform inputs and tensors to outputs
2.	SncEdge: Any block that transmits information from one layer to another layer without modifying the data
o	Has two sides; it does not matter which side connects to which layer
o	Holds input layer connection and output layer connections
o	Holds one single tensor
3.	SncTensor: Data abstraction containing data, tensor type, and metadata like data type, shape, and shape format
o	Used by layers and edges to communicate about layer data
4.	SncModule: Any block that acts as a layer to the outside and holds layer connection graphs on the inside
o	An abstraction that has many layers, modules, and edges
o	Has in and out port arrays
o	Module connects port index with outer edge array index by port type
o	Isolates inner layer connection graphs from the outside
o	Has a minimum of one input port and one output port
o	Can contain another module, but cannot contain a model
SNC API:
The SNC API is a set of interfaces and classes that provide a way to interact with SNC models. It includes:
1.	SNC: The main API entry point
2.	UUID: Unique IDs based on random creation, guaranteed to be unique from other SncComponent-based objects
3.	SncComponent: The base of all component-based classes
4.	SncTensor: Holds large amounts of same data type data with different dimensions
5.	SncEdge: Weak pointers are used to avoid circular references
6.	SncLayer: Uses JSON to store params, very flexible with data type
7.	SncPort
Error Handling:
Error handling is implemented based on pure Python. If some error happens in C++, it is not handled automatically at the Python or pybind level. Both error numbers and error logs need to be passed back.
Netron:
NNC file usage in Netron is based on flatbuffer. Later, a common IR from ML framework to the end of compilation needs to be made. NNC can be embedded into SNC with more detailed information in SNC headers.
DAO:
DAO code in CPP. Every class has its DAO (layer DAO, model DAO, etc.). Can we have a single DAO that does all? DAO style converter to be developed. Single code as conversion. Embed Prajjwal code into old SNC conversion.
FP16 Models:
FP16 models are supported. The interface/data structure for FP16 models is as follows:
Use Case	System Operation
Describe SNC graph	ISNCNN()
Handle categorized information	ISNCCategorizedInformation()

Hybrid_with_1250_chunk (10):
I'd be happy to explain SNC in detail and in easy language.
What is SNC?
SNC stands for Samsung Neural Compute. It's a framework for building and optimizing neural networks. SNC provides a set of tools and APIs for developers to create, train, and deploy neural networks on various hardware platforms.
Key Components of SNC
1.	SncLayer: A block that holds data transformation metadata. It has input connections, output connections, tensors (like weights and bias), and layer parameters.
2.	SncEdge: A block that transmits information from one layer to another without modifying the data. It has input and output connections and a single tensor.
3.	SncTensor: A data abstraction that contains data, tensor type, and metadata like data type, shape, and shape format.
4.	SncModule: An abstraction that has multiple layers, modules, and edges. It has input and output port arrays and connects port indices with outer edge array indices by port type.
Benefits of SNC
1.	Faster: SNC is much faster than other frameworks.
2.	Parallel Running: SNC can run in parallel, making it more efficient.
3.	Framework Protocol Independent: SNC is protocol-independent, making it easier to integrate with other frameworks.
4.	Reduced Compile Time: SNC can reduce compile time, especially when using fp16.
5.	Reduced SCVT Traversal Time: SNC can reduce SCVT traversal time by using C++ SNC IR.
6.	Same Style of Error Template: SNC provides a consistent error template across modules, making it easier to generate, track, and categorize errors.
7.	Static Information Embedding: SNC can embed static information from each layer as meta-information, making it easier to use hardware and add kernel constraints.
8.	Unit Tests: SNC provides unit tests that are configurable and easy to use.
9.	Fine-Grained Control: SNC provides fine-grained control over the full chain, making it easier to optimize neural networks.
10.	Custom Layer Support: SNC supports custom layers, making it easier to embed user code in the middle of a model.
SNC API
The SNC API provides a set of functions and classes for building and optimizing neural networks. It includes:
1.	SNC: The main API entry point.
2.	UUID: Unique IDs based on random creation.
3.	SncComponent: The base class for all component-based classes.
4.	SncTensor: Holds large amounts of same data type data with different dimensions.
5.	SncEdge: Transmits information from one layer to another without modifying the data.
Future Work
The future work on SNC includes:
1.	SNC Conversion: Converting old SNC to new SNC.
2.	SNC Quantization: Developing a profiler, asymm quantizer, and Root HWgen.
3.	SNC API: Integrating SNC Graphen reader, SNC API pybind, and SNC Quant information.
4.	SNC Yaml Automation: Automating SNC Yaml.
5.	SNC Yaml Schema Reorganization: Reorganizing SNC Yaml schema.
6.	SNC Enhancement: Enhancing SNC with features like clone function, shape auto-calculate, and batch norm.
I hope this explanation helps you understand SNC in detail and in easy language!
Hybrod_with_1000_chunk (9):
What is SNC?
SNC stands for Samsung Neural Compressor. It's a tool designed to optimize and compress neural networks for various platforms and devices. SNC provides a flexible and efficient way to convert, compress, and optimize neural networks, making them suitable for deployment on edge devices, mobile devices, and other resource-constrained platforms.
Key Features of SNC:
1.	Configurable: SNC offers a high degree of configurability, allowing users to customize the optimization process to suit their specific needs.
2.	Easy to use: SNC provides an easy-to-use interface, making it simple for developers to integrate and optimize their neural networks.
3.	Fine-grained control: SNC offers fine-grained control over the optimization process, enabling developers to make targeted optimizations and achieve better performance.
4.	Custom layer support: SNC supports custom layers, allowing developers to embed their own code and logic into the optimization process.
5.	Maintainable network: SNC enables developers to maintain the same network architecture while optimizing it for different platforms and devices.
SNC API:
The SNC API provides a set of functions and interfaces that developers can use to interact with SNC. The API is available in both C++ and Python versions, with the C++ version being the primary interface.
SNC Terminology:
1.	SncLayer: A block that holds data transformation metadata, including input connections, output connections, tensors, and layer parameters.
2.	SncEdge: A block that transmits information from one layer to another without modifying the data.
3.	SncTensor: A data abstraction that contains the data, tensor type, and metadata.
Usage and Design:
The SNC API is designed to be easy to use and provides a simple interface for developers to interact with SNC. The API is located at EDEN/SNC-API (samsung.net) and is available in both C++ and Python versions.
Future Work:
The SNC team is working on several future projects, including:
1.	FP8 support: Adding support for FP8 (Floating-Point 8) data type.
2.	New SDK code flow: Developing a new SDK code flow for SNC.
3.	Comparative study of IRs: Conducting a comparative study of IRs (Intermediate Representations) from various frameworks and open-source projects.
4.	Dynamic input handling: Implementing dynamic input handling for SNC.
5.	LLMs for Compiler Optimizations: Exploring the use of Large Language Models (LLMs) for compiler optimizations.
6.	NN Architectures: Studying Neural Network (NN) architectures, including AutoML, NAS, and LLMs.
SNC Layer Support:
SNC supports a wide range of layers, including:
1.	CONV2D+RELU: A convolutional layer with ReLU activation.
2.	MAXPOOL: A max pooling layer.
3.	RELU6: A ReLU activation function with a 6th power.
4.	LEAKY_RELU: A Leaky ReLU activation function.
SNC also supports various verifiers, including:
1.	ENNSimulator Operator Simulation Support: A verifier for EnnQuantizer.
2.	Old_snc_to_new_snc: A verifier for converting old SNC models to new SNC models.

 Question-6 Create a table of ssir team headcount for 2023
Hybrid_with_1750_chunk (8):

Based on the provided Confluence context chunks, I was able to find the information related to the SSIR team headcount for 2023.
The relevant context chunk is:
context 1 : # ADAS Work items
05 Dec 2022
SSIR team Headcount for 2023
[table-start]
SSIR ML Solution Team
| Mobile (2023) | IVI (2023) | ADAS (2023)
| Target HC | Target HC | Target HC
Device Driver | 4 | 2 | 2
Firmware | 5 | **** | 2
ENN, NNAPI, delegate | 5 | 1 | 2
GraphGen | 4 | ****
NPU Compiler | 14 | **** | 2
SDK (DL Tools) | 5 | **** | 3
Software Engineering | 3 | **** | 0
DSP Compiler | 0 | **** | 0
Total | 40 | 3 | 11
[table-end]
Based on this context chunk, the SSIR team headcount for 2023 is as follows:
Mobile (2023)	IVI (2023)	ADAS (2023)
40	3	11


Hybrid_with_1500_chunk (8):
Based on the provided context chunks, I can create the table for SSIR team headcount for 2023.
[table-start]
SSIR Team Headcount for 2023
| Mobile (2023) | IVI (2023) | ADAS (2023)
| Target HC | Target HC | Target HC
Device Driver | 4 | 2 | 2
Firmware | 5 | **** | 2
ENN, NNAPI, delegate | 5 | 1 | 2
GraphGen | 4 | ****
NPU Compiler | 14 | **** | 2
SDK (DL Tools) | 5 | **** | 3
Software Engineering | 3 | **** | 0
DSP Compiler | 0 | **** | 0
Total | 40 | 3 | 11
[table-end]

Hybrid_with_1250_chunk (10):
Based on the provided context chunks, I can create a table for the SSIR team headcount for 2023.
Here is the table:
Team	Mobile (2023)	IVI (2023)	ADAS (2023)
Device Driver	4	2	2
Firmware	5	-	2
ENN, NNAPI, delegate	5	1	2
GraphGen	4	-	-
NPU Compiler	14	-	2
SDK (DL Tools)	5	-	3
Software Engineering	3	-	0
DSP Compiler	0	-	0
Total	40	3	11
Note that the headcount for IVI (2023) is incomplete, as some rows have a dash (-) instead of a number.
Hybrid_with_1000_chunk (4):

Based on the provided context, I will create a table for the SSIR team headcount for 2023.
Team	Mobile (2023)	IVI (2023)	ADAS (2023)
Device Driver	4	2	2
Firmware	5	-	2
ENN, NNAPI, delegate	5	1	2
GraphGen	4	-	-
Note: The headcount for IVI (2023) and GraphGen under ADAS (2023) is not specified in the provided context.

Future Enhancement:
To improve accuracy and for reducing hallucination
•	Pre-processing of data more accurately, like a table should come within single chunk. It should not split in other chunk.
•	Testing model with different and more refined prompt.
